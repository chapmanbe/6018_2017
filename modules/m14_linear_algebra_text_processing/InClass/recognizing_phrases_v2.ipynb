{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrases\n",
    "\n",
    "So far we have only thought in terms of single words: \"lower\", \"lobe\", \"University\", \"of\", \"Utah\". But in reality often times multiple words form one unit of thought: \"University of Utah\". Our word vectors will do a better job of representing our text if we fist recognize these phrases. We are going to use the [gensim](https://radimrehurek.com/gensim/models/phrases.html) package to detect and transform these phrases.\n",
    "\n",
    "For example, the sentence, \"I am a faculty member in the departments of Biomedical Informatics and Radiology and Imaging Sciences at the University of Utah.\" would be transformed to \"I am a faculty member in the departments of Biomedical_Informatics and Radiology_and_Imaging_Sciences at the University_of_Utah.\"\n",
    "\n",
    "\"Biomedical_Informatics is an example of a **bigram phrase** and \"University_of_Utah\" is a **trigram phrase**. I guess \"Radiology_and_Imaging_Sciences\" is a quadgram phrase, but we will likely not try to detect phrases that long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Gensim Phrases Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nose.tools import assert_almost_equal, assert_true, assert_equal, assert_raises\n",
    "from numbers import Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upgrade to the latest version of gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install gensim -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "import getpass\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "from IPython.display import clear_output, display, HTML\n",
    "import pickle\n",
    "import gzip\n",
    "import seaborn as sns\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"rad_data.pickle.gz\", \"rb\") as f0:\n",
    "    rad_data = pickle.load(f0)\n",
    "rad_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"rad_vocabulary.pickle.gz\", \"rb\") as f0:\n",
    "    word_map = pickle.load(f0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's recompute the impression column but don't convert to lowercase first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_data[\"impression\"] = \\\n",
    "rad_data.apply(lambda row: get_impression(row[\"text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are our most common words \n",
    "### Hint: use a `Counter` and `most_common`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a function to pre-process our text\n",
    "\n",
    "* Lower case?\n",
    "* Digits?\n",
    "* Strip dates/times?\n",
    "* stop words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But first, write unit tests to test whether `preprocess` is functioning correctly\n",
    "#### Then write functionality to pass tests\n",
    "\n",
    "You might want to use the `strings` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.ascii_uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(txt):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do we return a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_true(type(preprocess(\"my name\"))== str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do we remove what we intend to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_equal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_equal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use our `preprocess` function to create a new column \"clean_impression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a TextBlob from all the text in `rad_data[\"clean_impression\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(preprocess(\" \".join(rad_data[\"clean_impression\"])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a function `train_phrases` that will train bigram and trigram detectors\n",
    "\n",
    "* We want to be able to ignore common terms in our phrase detection\n",
    "* We want to be able to specify the minimum number of occurences in our text to be considered a phrase\n",
    "* Return a dictionary of detectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write unit tests to determine whether `train_phrases` is working as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_phrases(blob, common_terms=None, min_count=5):\n",
    "    sentences = [s.words for s in blob.sentences]\n",
    "    if common_terms == None:\n",
    "        common_terms = []\n",
    "    phrases = Phrases(sentences, common_terms=common_terms, \n",
    "                      min_count=min_count)\n",
    "    bigram = Phraser(phrases)\n",
    "    trigram = Phrases(bigram[sentences])\n",
    "    \n",
    "    return {\"bigram\":bigram, \"trigram\":trigram}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_terms = [\"of\", \"with\", \"without\", \"and\", \"or\", \"the\", \"a\"]\n",
    "generators = train_phrases(blob, common_terms=common_terms, min_count=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a function that takes a `TextBlob` instance and phrase generators and returns a string of text\n",
    "#### Unit tests first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phrased_text(blob, generators):\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_phrased_text(TextBlob(\"There is a mass in the left lower lobe\"), \n",
    "                generators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_true()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_true()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrased_txt = get_phrased_text(blob, generators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What phrases did we detect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_phrases = set([w for w in phrased_txt.split() if \"_\" in w])\n",
    "print(len(found_phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How often did each phrase occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrased_blob = TextBlob(phrased_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counted_phrases = Counter([w for w in phrased_blob.words if \"_\" in w])\n",
    "counted_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phrase, count in list(counted_phrases.items())[:100]:\n",
    "    print(\"%s\\t%03d\"%(phrase.ljust(40),count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a word vector vocabulary using only words and phrases that occur more than N times\n",
    "### How to choose N?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is our vocabulary from phrased_txt (how many unqiue words)?\n",
    "\n",
    "Why use `TextBlob.words` instead of just `phrased_txt.split()`?\n",
    "\n",
    "#### why is `phrased_blob = TextBlob(phrased_txt)` fast and `print(len(set(phrased_blob.words)))` slow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrased_blob = TextBlob(phrased_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(phrased_blob.words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot([c[1] for c in phrased_blob_count if c[1] > 500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([w for w in lcounted_phrases if w[1]>10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vwords = [w for w in lcounted_phrases if w[1]>100 and w[0] not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining Similarity Between Reports\n",
    "* CXR vs CT vs MR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_data[rad_data[\"text\"].str.contains(\"MRI\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Report Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_reports = rad_data.shape[0]\n",
    "while True:\n",
    "    try:\n",
    "        i = int(input(\"Enter a number between 0 and %d. otherwise to quit\"%num_reports))\n",
    "        clear_output()\n",
    "\n",
    "        if i < 0 or i >=num_reports:\n",
    "            break\n",
    "        txt = TextBlob(rd.sub(\"\"\"d\"\"\", rad_data.iloc[i]['text'].strip().lower()))\n",
    "        display(HTML(\"<>%s</p>\"%\" \".join(trigram_generator[bigram_generator[txt.tokens]])))\n",
    "        \n",
    "    except ValueError:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangling Doesn't Always Do What You Want\n",
    "\n",
    ">technique : multiplanar_td and td-weighted_images of the brain with gadolinium_according to standard departmental protocol ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
